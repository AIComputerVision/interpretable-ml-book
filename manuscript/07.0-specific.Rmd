# Model-Specific Methods {#example-based}

Interpretation methods that are model-specific only work for a special class of machine learning models and require access to the parameters of the model (e.g. the weights) or influences the training process.

- blurry line between model-specific method and interpretable model. interpreting parameters can be seen as model-specific interpretation method.
- here, model-specific more if a lot more complex, but I acknowledge that it is not clear cut.


Two distictions:
- during training, e.g. fit only monotonic relationships
- after training, e.g. interpretation of neurons

can be more powerful than model-agnostic methods, since access to the model and therefore insight or influence in the mechanism that actually makes the predictions.

This chapter is used a bit different than the model-agnostic chapter.
Here we focus on the type of model / task and then have a chapter for it.


The chapters in this part cover model-specific interpretation methods for the following models / tasks (at least what I have planned so far):

<!--TODO: Write a short sentence for each, as in model-agnostic or example-based -->

- Survival analysis
- Recommender systems
- Convolutional Neural Networks - Feature Visualization
- Convolutional Neural Networks - Pixel Attribution (Integrated Gradients (IG), LRP, DeepLift)
- Random Forests and other tree ensembles
- Boosting - Monotonicity constraints
- NLP?

